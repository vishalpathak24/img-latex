{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/vishalpathak24/img-latex.git\n",
        "%cd img-latex/img-latex"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "blUrp84zGByT",
        "outputId": "7d2124e9-7758-4c5e-e4d5-1d48028f2638"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'img-latex'...\n",
            "remote: Enumerating objects: 19, done.\u001b[K\n",
            "remote: Counting objects: 100% (19/19), done.\u001b[K\n",
            "remote: Compressing objects: 100% (15/15), done.\u001b[K\n",
            "remote: Total 19 (delta 1), reused 19 (delta 1), pack-reused 0 (from 0)\u001b[K\n",
            "Receiving objects: 100% (19/19), 8.92 KiB | 8.92 MiB/s, done.\n",
            "Resolving deltas: 100% (1/1), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torchserve torch-model-archiver torch-workflow-archiver"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "ym4eYMaHJMUl",
        "outputId": "9b96517d-4b54-465c-af22-05a9a474fec6"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting torchserve\n",
            "  Downloading torchserve-0.12.0-py3-none-any.whl.metadata (1.4 kB)\n",
            "Collecting torch-model-archiver\n",
            "  Downloading torch_model_archiver-0.12.0-py3-none-any.whl.metadata (1.4 kB)\n",
            "Collecting torch-workflow-archiver\n",
            "  Downloading torch_workflow_archiver-0.2.15-py3-none-any.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from torchserve) (11.0.0)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from torchserve) (5.9.5)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from torchserve) (24.2)\n",
            "Requirement already satisfied: wheel in /usr/local/lib/python3.10/dist-packages (from torchserve) (0.45.1)\n",
            "Collecting enum-compat (from torch-model-archiver)\n",
            "  Downloading enum_compat-0.0.3-py3-none-any.whl.metadata (954 bytes)\n",
            "Downloading torchserve-0.12.0-py3-none-any.whl (42.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.2/42.2 MB\u001b[0m \u001b[31m23.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading torch_model_archiver-0.12.0-py3-none-any.whl (16 kB)\n",
            "Downloading torch_workflow_archiver-0.2.15-py3-none-any.whl (12 kB)\n",
            "Downloading enum_compat-0.0.3-py3-none-any.whl (1.3 kB)\n",
            "Installing collected packages: torch-workflow-archiver, enum-compat, torchserve, torch-model-archiver\n",
            "Successfully installed enum-compat-0.0.3 torch-model-archiver-0.12.0 torch-workflow-archiver-0.2.15 torchserve-0.12.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pwd"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VDdisCNtJPys",
        "outputId": "d7b17392-5ded-4e33-dd8c-7dd26be916c3"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/img-latex\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir ../../sample-images/\n",
        "!cp /content/drive/MyDrive/Colab\\ Notebooks/Image2Latex/sample-images/* ../../sample-images/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dHNSqCM0OSw4",
        "outputId": "8ce95bed-3bcf-4004-b60f-b9cdedab2562"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mkdir: cannot create directory ‘../../sample-images/’: File exists\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import VisionEncoderDecoderModel\n",
        "from transformers.models.nougat import NougatTokenizerFast\n",
        "from nougat_latex import NougatLaTexProcessor\n",
        "import torch"
      ],
      "metadata": {
        "id": "-0h4fyCaNB8G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model Basic Usage"
      ],
      "metadata": {
        "id": "1f2okLxWM0DY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_name = \"Norm/nougat-latex-base\"\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "model = VisionEncoderDecoderModel.from_pretrained(model_name).to(device)\n",
        "\n",
        "tokenizer = NougatTokenizerFast.from_pretrained(model_name)\n",
        "latex_processor = NougatLaTexProcessor.from_pretrained(model_name)"
      ],
      "metadata": {
        "id": "tU6HTjbDMziv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from PIL import Image\n",
        "\n",
        "image = Image.open(\"../../sample-images/lt-2.jpg\")\n",
        "if not image.mode == \"RGB\":\n",
        "    image = image.convert('RGB')"
      ],
      "metadata": {
        "id": "4XAfUA8POwgT"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pixel_values = latex_processor(image, return_tensors=\"pt\").pixel_values\n",
        "decoder_input_ids = tokenizer(tokenizer.bos_token, add_special_tokens=False,\n",
        "                              return_tensors=\"pt\").input_ids"
      ],
      "metadata": {
        "id": "uZUpOBjvUL41"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with torch.no_grad():\n",
        "    outputs = model.generate(\n",
        "        pixel_values.to(device),\n",
        "        decoder_input_ids=decoder_input_ids.to(device),\n",
        "        max_length=model.decoder.config.max_length,\n",
        "        early_stopping=True,\n",
        "        pad_token_id=tokenizer.pad_token_id,\n",
        "        eos_token_id=tokenizer.eos_token_id,\n",
        "        use_cache=True,\n",
        "        num_beams=5,\n",
        "        bad_words_ids=[[tokenizer.unk_token_id]],\n",
        "        return_dict_in_generate=True,\n",
        "    )"
      ],
      "metadata": {
        "id": "N_0eiP9CURaf"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sequence = tokenizer.batch_decode(outputs.sequences)[0]\n",
        "sequence = sequence.replace(tokenizer.eos_token, \"\").replace(tokenizer.pad_token, \"\").replace(tokenizer.bos_token, \"\")\n",
        "print(sequence)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_LQHaQV0UUI3",
        "outputId": "bb926135-8676-483b-a1e3-fde63cf915fe"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\\textstyle{\\frac{1}{3}}\\times\\left(6\\times{\\frac{4}{3}}\\right)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Creating Mar for inferencing"
      ],
      "metadata": {
        "id": "eUIg0_EULp0r"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import shutil\n",
        "\n",
        "shutil.make_archive('nougat', 'zip', 'img-latex/nougat_latex')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "pwp2UYMqLo9V",
        "outputId": "e9939ffb-df4e-4c60-ce1d-8cd63002b16e"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/img-latex/img-latex/nougat.zip'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.save(model.state_dict(), 'model.pt')"
      ],
      "metadata": {
        "id": "7sm_UUvKMODu"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!torch-model-archiver --model-name img-latex \\\n",
        "--version 1.0 --model-file model.py \\\n",
        "--serialized-file model.pt \\\n",
        "--handler handler.py \\\n",
        "--extra-files \"nougat.zip\""
      ],
      "metadata": {
        "id": "to8q2DwEUu8b"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir ../../model-store/\n",
        "!mv img-latex.mar ../../model-store/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fhauiSnBVqDi",
        "outputId": "9d0190f5-6950-4cd9-fc01-649e92c4e01c"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mkdir: cannot create directory ‘../../model-store/’: File exists\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!torchserve --model-store ../../model-store/ --models img-latex=img-latex.mar &"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "04-y7MqLU_Hx",
        "outputId": "badab015-c52f-45a8-de08-7e9df7c112d2"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING: sun.reflect.Reflection.getCallerClass is not supported. This will impact performance.\n",
            "2024-12-16T12:13:38,056 [INFO ] main org.pytorch.serve.servingsdk.impl.PluginsManager -  Loading snapshot serializer plugin...\n",
            "nvidia-smi not available or failed: Cannot run program \"nvidia-smi\": error=2, No such file or directory\n",
            "2024-12-16T12:13:38,147 [DEBUG] main org.pytorch.serve.util.ConfigManager - xpu-smi not available or failed: Cannot run program \"xpu-smi\": error=2, No such file or directory\n",
            "2024-12-16T12:13:38,151 [WARN ] main org.pytorch.serve.util.ConfigManager - Your torchserve instance can access any URL to load models. When deploying to production, make sure to limit the set of allowed_urls in config.properties\n",
            "2024-12-16T12:13:38,227 [INFO ] main org.pytorch.serve.util.TokenAuthorization - \n",
            "######\n",
            "TorchServe now enforces token authorization by default.\n",
            "This requires the correct token to be provided when calling an API.\n",
            "Key file located at /content/img-latex/img-latex/key_file.json\n",
            "Check token authorization documenation for information: https://github.com/pytorch/serve/blob/master/docs/token_authorization_api.md \n",
            "######\n",
            "\n",
            "2024-12-16T12:13:38,227 [INFO ] main org.pytorch.serve.servingsdk.impl.PluginsManager - Initializing plugins manager...\n",
            "2024-12-16T12:13:38,396 [INFO ] main org.pytorch.serve.metrics.configuration.MetricConfiguration - Successfully loaded metrics configuration from /usr/local/lib/python3.10/dist-packages/ts/configs/metrics.yaml\n",
            "2024-12-16T12:13:38,525 [INFO ] main org.pytorch.serve.ModelServer - \n",
            "Torchserve version: 0.12.0\n",
            "TS Home: /usr/local/lib/python3.10/dist-packages\n",
            "Current directory: /content/img-latex/img-latex\n",
            "Temp directory: /tmp\n",
            "Metrics config path: /usr/local/lib/python3.10/dist-packages/ts/configs/metrics.yaml\n",
            "Number of GPUs: 0\n",
            "Number of CPUs: 2\n",
            "Max heap size: 3246 M\n",
            "Python executable: /usr/bin/python3\n",
            "Config file: N/A\n",
            "Inference address: http://127.0.0.1:8080\n",
            "Management address: http://127.0.0.1:8081\n",
            "Metrics address: http://127.0.0.1:8082\n",
            "Model Store: /content/model-store\n",
            "Initial Models: img-latex=img-latex.mar\n",
            "Log dir: /content/img-latex/img-latex/logs\n",
            "Metrics dir: /content/img-latex/img-latex/logs\n",
            "Netty threads: 0\n",
            "Netty client threads: 0\n",
            "Default workers per model: 2\n",
            "Blacklist Regex: N/A\n",
            "Maximum Response Size: 6553500\n",
            "Maximum Request Size: 6553500\n",
            "Limit Maximum Image Pixels: true\n",
            "Prefer direct buffer: false\n",
            "Allowed Urls: [file://.*|http(s)?://.*]\n",
            "Custom python dependency for model allowed: false\n",
            "Enable metrics API: true\n",
            "Metrics mode: LOG\n",
            "Disable system metrics: false\n",
            "Workflow Store: /content/model-store\n",
            "CPP log config: N/A\n",
            "Model config: N/A\n",
            "System metrics command: default\n",
            "Model API enabled: false\n",
            "2024-12-16T12:13:38,554 [INFO ] main org.pytorch.serve.ModelServer - Loading initial models: img-latex.mar\n",
            "2024-12-16T12:13:38,585 [INFO ] main org.pytorch.serve.archive.model.ModelArchive - createTempDir /tmp/models/404702df3aea4c89900d0c102a673075\n",
            "2024-12-16T12:13:38,586 [WARN ] main org.pytorch.serve.ModelServer - Failed to load model: img-latex.mar\n",
            "org.pytorch.serve.archive.model.ModelNotFoundException: Model not found at: img-latex.mar\n",
            "\tat org.pytorch.serve.archive.model.ModelArchive.downloadModel(ModelArchive.java:118) ~[model-server.jar:?]\n",
            "\tat org.pytorch.serve.wlm.ModelManager.createModelArchive(ModelManager.java:185) ~[model-server.jar:?]\n",
            "\tat org.pytorch.serve.wlm.ModelManager.registerModel(ModelManager.java:143) ~[model-server.jar:?]\n",
            "\tat org.pytorch.serve.ModelServer.initModelStore(ModelServer.java:266) [model-server.jar:?]\n",
            "\tat org.pytorch.serve.ModelServer.startRESTserver(ModelServer.java:399) [model-server.jar:?]\n",
            "\tat org.pytorch.serve.ModelServer.startAndWait(ModelServer.java:124) [model-server.jar:?]\n",
            "\tat org.pytorch.serve.ModelServer.main(ModelServer.java:105) [model-server.jar:?]\n",
            "2024-12-16T12:13:38,609 [INFO ] main org.pytorch.serve.ModelServer - Initialize Inference server with: EpollServerSocketChannel.\n",
            "2024-12-16T12:13:40,790 [INFO ] main org.pytorch.serve.ModelServer - Torchserve stopped.\n",
            "java.io.IOException: Failed to bind to address: http://127.0.0.1:8080\n",
            "\tat org.pytorch.serve.ModelServer.initializeServer(ModelServer.java:354)\n",
            "\tat org.pytorch.serve.ModelServer.startRESTserver(ModelServer.java:415)\n",
            "\tat org.pytorch.serve.ModelServer.startAndWait(ModelServer.java:124)\n",
            "\tat org.pytorch.serve.ModelServer.main(ModelServer.java:105)\n",
            "Caused by: io.netty.channel.unix.Errors$NativeIoException: bind(..) failed: Address already in use\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "\n",
        "files.download('../../model-store/img-latex.mar')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "meo1oZdgZDV9",
        "outputId": "180be420-5915-4c9e-bd4e-72c888675623"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_3168988d-414d-41d4-aafa-72605550a462\", \"img-latex.mar\", 1293241540)"
            ]
          },
          "metadata": {}
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}